{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288c4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d28c8",
   "metadata": {},
   "source": [
    "The preceding code imports your scraping tools: the Browser instance from Splinter, the Beautiful Soup object, and the driver object for Chrome (ChromeDriverManager). Notice that the code uses the soup alias so that later referencing the Beautiful Soup object will be simpler.\n",
    "\n",
    "In the next cell, set the executable path and initialize a browser by entering the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a984d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7e6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Quotes to Scrape site\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa49bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e561b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>Top Ten tags</h2>\n",
      "Top Ten tags\n"
     ]
    }
   ],
   "source": [
    "# Scrape the Title\n",
    "\n",
    "h2 = html_soup.find('h2')\n",
    "\n",
    "title = h2.text\n",
    "\n",
    "print(h2)\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25632d0a",
   "metadata": {},
   "source": [
    "In the preceding code, the first print statement displays <h2>Top Ten tags</h2>. And, the second print statement displays Top Ten tags. To understand how we got those, let’s go over the first two lines of code:\n",
    "\n",
    "On the h2 = html_soup.find('h2') line, we use the html_soup object that we created earlier and call its find method to search for the <h2 /> tag. Printing the result thus produces <h2>Top Ten tags</h2>.\n",
    "\n",
    "On the title = h2.text line, we extract just the text from the <h2 /> tag by adding .text to the end of the code. This extracts the text attribute, so printing it produces only the title text of Top Ten tags.\n",
    "\n",
    "NOTE\n",
    "We could also directly access the title text by using title = html_soup.find('h2').text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae64726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# Scrape the top ten tags\n",
    "\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "\n",
    "# tag_box\n",
    "\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "for tag in tags:\n",
    "  \n",
    "    word = tag.text\n",
    "    \n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b3ea7",
   "metadata": {},
   "source": [
    "Let's go over the preceding code:\n",
    "\n",
    "The first line, tag_box = html_soup.find('div', class_='tags-box'), assigns the results of a search to a new variable named tag_box. The search is for <div /> tags that have a class of tags-box.\n",
    "\n",
    "This search occurs in the HTML code that we parsed and stored in the html_soup variable earlier.\n",
    "\n",
    "The class_ argument contains an underscore (_). That’s because the word class is reserved for other uses in Python..\n",
    "\n",
    "The second line, tags = tag_box.find_all('a', class_='tag'), drills down further into the data in tag_box.\n",
    "\n",
    "This line uses the find_all method to search within tag_box. This time, we search through the parsed results that are stored in our tag_box variable to find all the anchor (a) elements that belong to the tag class.\n",
    "\n",
    "We use find_all because we want to capture all the results rather than a single or specific one.\n",
    "\n",
    "NOTE\n",
    "The Beautiful Soup find method returns the first search result. The find_all method returns all the results.\n",
    "\n",
    "We added a for loop. This loop cycles through the tags in the tags variable, extracts the HTML code from each, and then prints only the text of each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43da8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
